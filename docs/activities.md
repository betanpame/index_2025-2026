# Step-by-Step Learning Activities

This guide provides detailed day-by-day activities for each project, ensuring structured learning and skill development.

---

## üîß Pre-Project Setup (Essential for All Projects)

Before starting any project, complete these foundational steps:

### 1. Development Environment Setup

**What**: Install and configure your local development environment  
**Why**: Having a proper setup prevents frustration and enables efficient learning

**Actions**:
- Install Python 3.9+ and create virtual environments for each project
- Set up PostgreSQL database locally (use Docker if preferred)
- Install Git and configure with your GitHub credentials
- Choose and configure your IDE (VS Code recommended with Python and SQL extensions)
- Install Jupyter Notebook for data exploration and documentation

### 2. GitHub Portfolio Preparation

**What**: Create a professional GitHub profile for your data portfolio  
**Why**: Employers will review your GitHub to assess your skills and project quality

**Actions**:
- Create a professional README.md for your GitHub profile
- Set up a clear repository naming convention (e.g., `project-01-goodreads-analytics`)
- Learn basic Git workflow: add, commit, push, pull requests
- Practice writing clear commit messages that describe your changes

### 3. Database Fundamentals Review

**What**: Ensure solid understanding of relational database concepts  
**Why**: SQL and database design are fundamental to all data work

**Actions**:
- Review ERD (Entity Relationship Diagram) concepts
- Practice basic SQL: SELECT, WHERE, GROUP BY, JOINs, subqueries
- Understand data types, constraints, and normalization
- Learn about indexes and their impact on query performance

---

## üìä Project 1: Goodreads Books Analytics

### Week 1: Foundation Building

#### Day 1-2: Data Exploration
- Download Goodreads dataset and examine file structure
- Load data into Pandas and perform initial inspection (`.info()`, `.describe()`, `.head()`)
- Identify missing values, duplicates, and data quality issues
- Document findings in a Jupyter notebook with clear explanations

#### Day 3-4: Database Setup
- Create PostgreSQL database and design table schema
- Import CSV data using Python or SQL COPY commands
- Write data validation queries to ensure successful import
- Practice different JOIN operations between related tables

#### Day 5-7: Basic Analysis
- Write SQL queries to answer basic business questions
- Calculate summary statistics (average ratings, publication trends)
- Create simple visualizations with matplotlib/seaborn
- Document methodology and findings

### Week 2: Advanced Analysis & Visualization

#### Day 8-10: Statistical Analysis
- Perform correlation analysis between variables (rating vs. pages, publication year vs. ratings)
- Create distribution plots and identify patterns
- Apply basic statistical tests to validate hypotheses
- Learn about data storytelling principles

#### Day 11-14: Visualization & Documentation
- Create professional charts with proper titles, labels, and styling
- Build a cohesive narrative connecting your visualizations
- Write comprehensive README with methodology, findings, and conclusions
- Practice presenting insights to non-technical audience

---

## üìà Project 2: Best-Selling Books Market Analysis

### Week 1: Advanced SQL & Git Workflows

#### Day 1-3: Advanced SQL Techniques
- Learn CTEs (Common Table Expressions) for complex queries
- Master window functions for ranking and running totals
- Practice subqueries and their optimization
- Understand query execution plans and performance tuning

#### Day 4-7: Git Branching Strategy
- Learn Git branching (feature branches, main branch protection)
- Practice merge conflicts resolution
- Implement code review process using pull requests
- Set up automated testing for SQL queries

### Week 2: Business Intelligence Development

#### Day 8-10: Data Modeling
- Design dimensional model (fact and dimension tables)
- Implement slowly changing dimensions (SCD) concepts
- Create data marts for specific business functions
- Learn about data warehouse design patterns

#### Day 11-14: Dashboard Creation
- Learn Power BI interface and data connection methods
- Design effective dashboards following UI/UX principles
- Implement interactive filters and drill-down capabilities
- Create executive summary views with KPIs

---

## üîÑ Project 3: Amazon Reviews ETL Pipeline

### Week 1: ETL Foundations

#### Day 1-3: Data Pipeline Design
- Learn ETL vs ELT approaches and when to use each
- Design data flow diagrams for your pipeline
- Understand data lineage and documentation importance
- Study error handling and data validation strategies

#### Day 4-7: Python ETL Development
- Write modular Python functions for data extraction
- Implement data cleaning and transformation logic
- Create reusable classes for different data sources
- Add logging and error handling to your scripts

### Week 2: Analytics & Visualization

#### Day 8-10: Advanced Data Analysis
- Perform text analysis on review data (word frequency, sentiment indicators)
- Create time series analysis of rating trends
- Build customer segmentation based on review behavior
- Calculate business metrics (average review length, rating distribution)

#### Day 11-14: Comprehensive Visualization
- Create interactive dashboards with Plotly or similar tools
- Build geographic visualizations if location data available
- Implement drill-down capabilities in your charts
- Design executive summary with key insights and recommendations

---

## üèóÔ∏è Project 4: Computer Components Data Platform

### Week 1: Multi-Source Integration

#### Day 1-3: Data Architecture Planning
- Map data sources and identify integration challenges
- Design unified data model accommodating all sources
- Plan data transformation and standardization steps
- Document data governance and quality requirements

#### Day 4-7: Integration Implementation
- Build Python scripts to handle multiple file formats
- Implement data validation and quality checks
- Create automated data refresh processes
- Test error scenarios and build resilience

### Week 2: Advanced Analytics & Automation

#### Day 8-10: Complex Analytics
- Implement advanced SQL analytics (percentiles, moving averages)
- Create predictive insights using statistical methods
- Build automated alerting for data quality issues
- Develop performance monitoring and optimization

#### Day 11-14: Professional Deployment
- Create comprehensive documentation and user guides
- Implement version control for data transformations
- Build deployment scripts for easy environment setup
- Conduct end-to-end testing and performance validation

---

## ‚òÅÔ∏è Project 5: AWS Cloud Analytics Platform

### Week 1: AWS Environment & Architecture

#### Day 1-3: AWS Fundamentals
- Set up AWS account and understand billing/cost management
- Learn IAM roles, policies, and security best practices
- Understand AWS data services ecosystem and use cases
- Design serverless data architecture diagram

#### Day 4-7: Data Lake Implementation
- Create S3 buckets with proper naming and organization
- Implement data partitioning strategies for performance
- Set up AWS Glue Data Catalog for metadata management
- Learn about data formats (Parquet vs CSV) and compression

### Week 2: ETL & Analytics Development

#### Day 8-10: AWS Glue Development
- Create Glue jobs using visual editor and Python scripts
- Implement data transformation and quality checks
- Set up scheduling and monitoring for ETL jobs
- Learn debugging and troubleshooting techniques

#### Day 11-14: QuickSight Dashboard Creation
- Design and build interactive dashboards in QuickSight
- Implement calculated fields and advanced visualizations
- Set up automated data refresh and user access controls
- Create mobile-responsive dashboard layouts

---

## üìù Daily Activity Template

For each day of learning, follow this structure:

### Morning Session (2-3 hours)
1. **Review** (15 min): Review previous day's work and notes
2. **Learning** (45 min): Study new concepts, read documentation
3. **Practice** (60-90 min): Hands-on implementation and coding
4. **Document** (15 min): Write notes and commit progress

### Evening Session (1-2 hours)
1. **Problem-solving** (30-60 min): Debug issues, research solutions
2. **Enhancement** (30 min): Improve code quality, add comments
3. **Planning** (15 min): Plan next day's activities and goals

### Weekly Review
- **Friday afternoon**: Review week's progress, update GitHub
- **Sunday evening**: Plan upcoming week and adjust timeline if needed

---

## üéØ Learning Tips

### Effective Study Techniques
- **Active Learning**: Explain concepts out loud or write about them
- **Pomodoro Technique**: 25-minute focused work sessions with 5-minute breaks
- **Spaced Repetition**: Review concepts at increasing intervals
- **Project-Based Learning**: Apply new skills immediately to your project

### Problem-Solving Strategies
- **Read Error Messages Carefully**: Most errors contain helpful information
- **Google Effectively**: Include specific error messages and technology names
- **Use Documentation**: Official docs are often the best resource
- **Ask in Communities**: Post specific questions with context and code

### Progress Tracking
- **Daily Logs**: Keep a simple log of what you accomplished each day
- **Weekly Reflections**: What went well? What was challenging? What did you learn?
- **Milestone Celebrations**: Acknowledge progress and small wins
- **Adjust Timeline**: It's okay to take longer on complex topics

---

## üîó Navigation

- **[‚Üê Project Details](projects.md)** - Return to project descriptions
- **[Technology Glossary ‚Üí](glossary.md)** - Essential terms and definitions
- **[Career Resources](career.md)** - Professional development guidance
- **[Quality Standards](quality.md)** - Project completion criteria
- **[Learning Overview](overview.md)** - Overall learning path structure